{"chosen": "Here is a 160-200 word faithful scientific summary of the paper:\n\nThe SciReasoner model was developed to perform a variety of scientific tasks, including property prediction, sequence-to-sequence tasks, and generation tasks. The model was trained on a large corpus of scientific text and data, comprising scientific papers, patents, and databases. The authors assessed the performance of SciReasoner on multiple tasks, including molecular property prediction, sequence-to-sequence tasks, and generation tasks, and found that it outperformed state-of-the-art models on many of these tasks. \n\nIn property prediction tasks, SciReasoner demonstrated improved accuracy in predicting molecular properties such as solubility and melting point. For sequence-to-sequence tasks, the model exhibited enhanced", "rejected": "The SciReasoner model is a large language model designed for scientific reasoning. It is trained on a pretraining corpus of 206B tokens, which includes a diverse set of scientific data from various disciplines, such as DNA/RNA sequences, protein sequences, small molecules, and materials. The model is fine-tuned on a set of scientific tasks, including scientific translation, knowledge extraction, property prediction, and sequence generation. The model's performance is evaluated on several benchmarks, including GEMINI-2.5, Bio-GPT, and other models, and it demonstrates state-of-the-art performance in various tasks. \n\nThe model's architecture consists of four stages: pre-training, SFT (supervised fine-tuning), RL (reinforcement"}
{"chosen": "Title: A Framework for Reinforcement Learning with Binary Flexible Feedback (RLBFF)\n\nAbstract:\n\nThis study presents a novel framework, Reinforcement Learning with Binary Flexible Feedback (RLBFF), that integrates the strengths of Reinforcement Learning with Human Feedback (RLHF) and Reinforcement Learning with Verifiable Rewards (RLVR). The proposed approach addresses the limitations of RLHF by leveraging human feedback in the form of binary, interpretable principles and grounding Reward Model training as an entailment task. To evaluate the effectiveness of RLBFF, the authors conducted experiments on the RM-Bench benchmark and achieved state-of-the-art performance. The methodology involved:\n\n* Extracting binary, interpretable principles from natural language feedback\n* Grounding Reward Model training as", "rejected": "In a study on the performance of Reinforcement Learning with Human Feedback (RLHF) and Reinforcement Learning with Verifiable Rewards (RLVR), researchers have proposed a novel approach called Reinforcement Learning with Binary Flexible Feedback (RLBFF). This approach aims to bridge the gap between RLHF and RLVR, leveraging the strengths of both methods to develop more effective reward models. The researchers demonstrated the effectiveness of RLBFF by achieving state-of-the-art performance on RM-Bench, JudgeBench, and PrincipleBench, a new benchmark created to evaluate reward models' ability to follow specific principles. Additionally, they used RLBFF to align Qwen3-32B with RLBFF, achieving comparable performance to proprietary models like o3"}
{"chosen": "Here is a 3-5 sentence faithful scientific summary of the research paper \"SHINE: Training-Free Image Composition with Pretrained Text-to-Image Models\":\n\nThe SHINE framework is a training-free method for image composition that leverages pretrained text-to-image (T2I) models to seamlessly insert a subject into a background image. SHINE consists of three key components: Manifold-Steered Anchor (MSA) loss, Degradation-Suppression Guidance (DSG), and Adaptive Background Blending (ABB), which work together to preserve the surrounding scene's integrity and eliminate artifacts. By leveraging the prior knowledge embedded in T2I models, SHINE enables accurate and efficient image composition without the need for extensive training. The authors", "rejected": "The provided text is a preprint of a research paper that presents a new framework for image composition, called SHINE. The framework is designed to integrate a subject into a background image while preserving the structural integrity of the surrounding scene. The proposed framework is model-agnostic and consists of three main components: Manifold-Steered Anchor (MSA) loss, Degradation-Suppression Guidance (DSG), and Adaptive Background Blending (ABB).\n\nThe MSA loss is designed to optimize the noisy latent during the denoising process, steering it toward faithfully capturing the reference subject while preserving the structural integrity of the background. The DSG loss is used to steer the denoising trajectory away from low-quality distributions, and the ABB"}
{"chosen": "Here is a 160-200 word faithful scientific summary focusing on methodology and results:\n\nThis study investigates the properties of maxout polytopes, which are defined by feedforward neural networks with maxout activation functions and non-negative weights after the first layer. The authors employ a rigorous mathematical approach to characterize the parameter spaces and extremal f-vectors of maxout polytopes for shallow networks. They utilize a combinatorial and geometric perspective to analyze the polytopes and derive their properties.\n\nThe authors analyze the separating hypersurfaces that arise when a layer is added to the network, revealing insights into the structure of the polytopes. A key finding is that maxout polytopes are cubical for generic networks without bottlenecks", "rejected": "The article discusses maxout polytopes, which are polytopes that arise from neural networks with maxout activation function and non-negative weights after the first layer. The authors characterize the parameter spaces and extremal f-vectors of maxout polytopes for shallow networks and study the separating hypersurfaces that arise when a layer is added to the network. They also show that maxout polytopes are cubical for generic networks without bottlenecks.\n\nThe authors also provide a detailed study of the family of polytopes with controlled depth, known as maxout polytopes. They introduce two specific families of cubical polytopes, B_d and B_d', which generalize the polytope on the right in Figure 1"}
{"chosen": "Here is a 160-200 word faithful scientific summary focusing on methodology and results:\n\nThis study presents the Gaussian Process Hyperbolic Dynamical Model (GPHDM), an innovative approach that learns latent representations of motions while preserving their hierarchical structure and temporal dynamics. The GPHDM extends the Gaussian Process Dynamical Model (GPDM) to the hyperbolic manifold and integrates it with the taxonomy-aware framework of the Gaussian Process Hyperbolic Latent Variable Model (GPHLVM). This combination enables the model to capture the hierarchical structure of motions and their temporal dependencies. Three novel motion generation mechanisms are proposed: two probabilistic recursive approaches and a method based on pullback-metric geodesics. These mechanisms ensure that generated motions are both", "rejected": "This paper proposes a novel approach to generate human-like motions for robots by leveraging hyperbolic geometry, taxonomy structures, and dynamics priors as inductive biases. The authors present the Gaussian Process Hyperbolic Dynamical Model (GPHDM), a generative model that learns latent representations that preserve the hierarchical structure and temporal dynamics of human motions. The GPHDM is composed of a Gaussian Process Latent Variable Model (GPLVM) on a hyperbolic manifold and a hyperbolic dynamics prior that encourages the latent variables to form smooth trajectories.\n\nThe authors evaluate the GPHDM and three dynamic motion generation strategies on a hand grasp taxonomy dataset. The results show that the GPHDM outperforms other models in terms of preserving the taxonomy"}
{"chosen": "Here is a 3-5 sentence faithful scientific summary of the provided text:\n\nNewtonGen is a physics-consistent text-to-video generation framework that integrates a data-driven video generator with a physics-informed neural ordinary differential equation (Neural Newtonian Dynamics, NND) model. The NND model learns to predict the dynamics of various motions from a small set of physically accurate examples and forecasts future physical states. NewtonGen was evaluated on 12 dynamic video generation tasks, demonstrating its ability to generate physically consistent and controllable videos that outperform other baselines. The framework consists of two stages: a training stage where the NND model is trained on physics-clean data, and a prediction stage where the learned dynamics are used to generate new videos.", "rejected": "NewtonGen is a novel framework for generating physically-consistent and controllable text-to-video content. It combines data-driven synthesis with learnable physical principles, specifically employing Neural Newtonian Dynamics (NND) to model and predict a variety of Newtonian motions. This allows for physically consistent video synthesis with precise parameter control. The authors evaluate NewtonGen on 12 different dynamic video generation tasks, demonstrating its physical consistency and parameter controllability."}
{"chosen": "Here is a 160-200 word faithful scientific summary of the methodology and results:\n\nThe authors introduce Probability Smoothing Policy Optimization (PSPO), a novel method that replaces ratio clipping in reinforcement learning for large language models. PSPO smooths the current policy's probabilities towards the old behavior policy before computing the importance ratio, creating a soft trust region that discourages large updates. This approach preserves gradient signal and avoids the drawbacks of ratio clipping. The authors implement PSPO within Group Relative Policy Optimization (GRPO) and evaluate its performance on various mathematical reasoning tasks.\n\nResults show that GR-PSPO outperforms GRPO with clipping on all datasets, achieving gains of over 20% on GSM8K for both the 0.5B", "rejected": "The authors propose a novel method called Probability Smoothing Policy Optimisation (PSPO) as an alternative to ratio clipping in reinforcement learning for large language models. PSPO smooths the current policy's probabilities towards the old policy before computing the importance ratio, creating a \"soft trust region\" that discourages large, destabilizing updates while preserving gradient signal. The authors instantiate PSPO within Group Relative Policy Optimization (GRPO) and fine-tune the Qwen2.5-0.5B and 1.5B models on the GSM8K dataset, evaluating on GSM8K, ASDiv, SVAMP, and MATH-500. The results show that PSPO outperforms clipped GRPO on all datasets, achieving gains"}
{"chosen": "Here is a 160-200 word faithful scientific summary focusing on methodology and results:\n\nThe study \"No Prior, No Leakage: Revisiting Reconstruction Attacks in Trained Neural Networks\" by Yehonathan Refael et al. examines the limitations of reconstruction attacks in trained neural networks. The authors employ a theoretical framework to analyze the objective function underlying the reconstruction attack, demonstrating that it admits ubiquitous global minima. This finding implies that reconstruction attacks are unreliable without prior knowledge of the network's internal workings. To investigate the conditions under which training set leakage is possible, the authors provide a rigorous analysis of the attack's effectiveness. Their results show that exact duplication of training examples occurs only by chance, indicating that the attack's success is not guaranteed.", "rejected": "No Prior, No Leakage: Revisiting Reconstruction Attacks in Trained Neural Networks Yehonathan Refael1* Guy Smorodinsky2* Ofir Lindenbaum3 Itay Safran2 1Tel Aviv University 2Ben-Gurion University of the Negev 3Bar-Ilan University September 26, 2025 Abstract The memorization of training data by neural networks raises pressing concerns for privacy and security. Recent work has shown that, under certain conditions, portions of the training set can be reconstructed directly from model parameters. Some of these methods exploit implicit bias toward margin maximization, suggesting that properties often regarded as beneficial for generalization may actually compromise privacy. Yet despite striking empirical demonstrations, the reliability of"}
{"chosen": "Here is a 160-200 word faithful scientific summary focusing on methodology and results:\n\nResearchers have developed a Post-Training Quantization (PTQ) framework for Visual Geometry Grounded Transformers (VGGTs), called QuantVGGT. The proposed framework aims to reduce the computational and memory costs of VGGTs, which are large-scale models that excel in 3D reconstruction tasks. To address the challenges of quantizing VGGTs, the researchers propose a dual-stage smoothing scheme, called Dual-Smoothed Fine-Grained Quantization, to mitigate the effects of heavy-tailed activation distributions caused by data-independent special tokens. Additionally, a calibration strategy is employed to stabilize the selection of calibration samples, which is crucial for 3", "rejected": "Recent advances in learning-based 3D reconstruction have achieved remarkable progress, especially with the use of large-scale transformers. Visual Geometry Grounded Transformers (VGGTs) have made a significant impact in this field by unifying multiple 3D tasks, including dense depth estimation, point map regression, camera pose prediction, and point tracking. However, the billion-scale parameterization of VGGT incurs significant computational and memory costs, severely restricting its real-world deployment.\n\nTo address this challenge, researchers proposed the first systematic investigation of Post-Training Quantization (PTQ) for VGGT and introduced a tailored framework, QuantVGGT. This framework addresses the unique obstacles of PTQ in compressing billion-scale VGGTs, which include"}
{"chosen": "Here is a 160-200 word faithful scientific summary of the paper:\n\nThis study proposes two novel algorithms, Algorithm 1 and Algorithm 2, for computing the optimal robust recourse in generalized linear models under Lp-bounded model changes. The objective of robust recourse is to provide individuals who received unfavorable outcomes from algorithmic decision-making systems with a cost-efficient suggestion to achieve the desired outcome, while ensuring that the recourse remains valid even in the presence of slight model changes. The authors compare their algorithms with existing approaches, including ROAR and RBR, on real-world datasets. The results show that Algorithm 1 and Algorithm 2 achieve a significantly lower price of recourse, up to several orders of magnitude, compared to prior work. The study also", "rejected": "The paper \"Optimal Robust Recourse with Lp-Bounded Model Change\" presents a novel approach to algorithmic recourse, which provides individuals who have been given undesirable outcomes by machine learning systems with suggestions on how to achieve a desired outcome. The authors propose a new algorithm that provably computes the optimal robust recourse for generalized linear models when the model changes are measured using the Lp norm, where p >= 1 but p \u2260 \u221e. The algorithm is designed to minimize the price of recourse, which is the cost of modifying the input instance to achieve the desired outcome, while also ensuring that the model remains robust to model changes.\n\nThe authors' approach is an improvement over existing methods that assume fixed models or use non-optimal algorithms,"}
